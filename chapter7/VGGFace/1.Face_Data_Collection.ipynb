{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:right\">\n",
    "    项目名称：<b>人脸识别</b><br/>\n",
    "设计：董相志<br/>\n",
    "学号：220100<br/>\n",
    "日期：2020.10<br/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一阶段：数据采集，构建训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目分为四个阶段：<br/><br/>\n",
    "【1】第一阶段：数据采集，构建训练集。<br/>\n",
    "【2】第二阶段：构建卷积网络，训练人脸识别模型。<br/>\n",
    "【3】第三阶段：人脸相似度计算与比较。<br/>\n",
    "【4】第四阶段：基于<b>One-Shot Learning</b>（单样本学习）实现人脸实时检测识别。<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import cv2   \n",
    "import dlib   # 用dlib做人脸检测\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要安装dlib，请使用命令：<br/>\n",
    "pip install cmake -i https://pypi.tuna.tsinghua.edu.cn/simple<br/>\n",
    "pip install dlib -i https://pypi.tuna.tsinghua.edu.cn/simple<br/>\n",
    "如果dlib安装提示错误，请注意观察，提示信息是否为：You need to install Visual Studio for C++<br/>\n",
    "此时，你需要安装Visual Studio for C++ 2017或2019版本<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 还有一个更简洁的方法，下载dlib的whl文件，将其拷贝到安装目录，用pip命令实现本地安装\n",
    "例如：假定你的工作环境为Python3.8。下载与3.8对应的dlib安装包。执行命令：<br/>\n",
    "#### pip install dlib-19.19.0-cp38-cp38-win_amd64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>运行下面的程序之前，应该首先在当前dataset目录下创建存放训练集和验证集图像的子目录：</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 目录结构：\n",
    "<img src = \"images/directory.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 运行下面的程序格，每运行一次，可完成一人的数据采集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已经完成了 89 帧检测，共保存了 86 幅脸部图像\n"
     ]
    }
   ],
   "source": [
    "# 定义面部正面探测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 打开摄像头或者打开视频文件\n",
    "cap = cv2.VideoCapture(0)  #参数设为0，可以从摄像头实时采集头像\n",
    "frame_count = 0  #帧计数\n",
    "face_count = 0  #脸部计数\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# 循环读取每一帧，对每一帧做脸部检测，按ESC键循环结束\n",
    "while True:  \n",
    "    ret, frame = cap.read()  #从摄像头或者文件中读取一帧\n",
    "    if (ret != True):\n",
    "        print('没有捕获图像，数据采集结束或者检查摄像头是否工作正常！')\n",
    "        break       \n",
    "    frame_count += 1  # 帧计数\n",
    "#     img_h, img_w, _ = np.shape(frame)  # 获取图像尺寸   \n",
    "    detected = detector(frame, 1)  #对当前帧检测,参数1表示上采样1次\n",
    "    faces = []   # 脸部图像列表  \n",
    "    if len(detected) > 0:  #当前帧检测到人脸图像\n",
    "        for i, d in enumerate(detected):  # 遍历\n",
    "            face_count += 1  # 人脸计数\n",
    "            # 脸部图像坐标与尺寸\n",
    "            x1,y1,x2,y2,w,h = d.left(),d.top(),d.right()+1,d.bottom()+1,\\\n",
    "                              d.width(), d.height()\n",
    "            # 脸部图像坐标\n",
    "            face =  frame[y1:y2 + 1, x1:x2 + 1, :]\n",
    "            # 将采集的图像自动分为训练集和验证集两部分，训练集占比75%，验证集占比25%\n",
    "            if (frame_count % 4 !=0):\n",
    "                #保存人脸图片到./dataset/train/目录,改变one目录，可保存采集的其他人图像\n",
    "                # 用one、two、three、four做为目录名，也代表人名标签\n",
    "                file_name = \"./dataset/train/one/\"+str(frame_count)+\"_one\"+str(i)+\".jpg\"\n",
    "            else:\n",
    "                #保存人脸图片到./dataset/valid/目录，改变one目录，可保存采集的其他人图像\n",
    "                file_name = \"./dataset/valid/one/\"+str(frame_count)+\"_one\"+str(i)+\".jpg\"\n",
    "            cv2.imwrite(file_name, face)  # 保存为文件\n",
    "            # 绘制边界框\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"already get : {frame_count}  faces\", \\\n",
    "                        (80, 80), font,1.2, (255, 0, 0), 3)\n",
    "    # 显示单帧检测结果\n",
    "    cv2.imshow(\"Face Detector\", frame)\n",
    "    # Esc键终止检测\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "print('已经完成了 {0} 帧检测，共保存了 {1} 幅脸部图像'.format(frame_count, face_count))\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>需要特别强调的是，上面的数据采集程序，首次成功运行后，采集的数据默认保存在如下目录中：<br/></font>\n",
    "<b>训练集目录：dataset/train/one<br/></b>\n",
    "<b>验证集目录：dataset/valid/one<br/></b>\n",
    "如果要采集第二个人的图像，请在重新运行上面程序格之前，将数据保存目录的代码中的<font color = 'red'>one修改为two。</font><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改one--》two，注意，有四处地方需要修改\n",
    "'''\n",
    "if (frame_count % 4 !=0):\n",
    "    file_name = \"./dataset/train/two/\"+str(frame_count)+\"_two\"+str(i)+\".jpg\"\n",
    "else:\n",
    "    file_name = \"./dataset/valid/two/\"+str(frame_count)+\"_two\"+str(i)+\".jpg\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本案例是一个通用程序，既可以从视频中采集图像，也可以从摄像头中采集图像。<br/>\n",
    "以摄像头为例，大家分别站在摄像头前面，做出各种姿态与表情。完成数据采集工作。<br/>\n",
    "数据采集完成后，应该分别检查目录one、two、three、four，看看是否单个目录中混杂了其他人的照片。这个工作是必要的，因为如果多个人一起站在摄像头前，有可能多个人的图像被采集到同一个目录里面。<br/>\n",
    "熟悉采集的数据之后，可以进一步做人工标记，重新调整划分训练集与验证集比例等。<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上面的工作结束后，恭喜您可以进行第二阶段的建模工作了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
