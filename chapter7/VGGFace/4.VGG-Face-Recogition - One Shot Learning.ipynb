{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:right\">\n",
    "    项目名称：<b>人脸识别</b><br/>\n",
    "设计：董相志<br/>\n",
    "学号：220100<br/>\n",
    "日期：2020.10<br/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四阶段：模仿刷脸门禁系统实时人脸识别\n",
    "基于<b>One-Shot Learning</b>（单样本学习）实现人脸实时检测与识别。<br/>\n",
    "### 设计摘要:\n",
    "【1】 将本单位的员工照片放入数据库，每位员工只有一张照片。本案例将员工照片存放于 \"./employee\"目录中。<br/>\n",
    "【2】 用 haarcascade 方法或者 dlib 方法或者mtcnn方法，从摄像头实时捕获人脸图像。<br/>\n",
    "【3】 用训练好的模型VGGFace Model分别提取员工的实时照片 与 数据库照片 的特征。<font color ='red'>其实更好的做法是将员工照片的特征单独存储。</font><br/>\n",
    "【4】 用余弦相似性将摄像头捕获的图像与员工数据库比对，匹配，开闸放行；否则，拒绝进入。<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 制作员工照片数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用下面的程序段采集几张员工照片放到employee目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import cv2   \n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# 定义面部正面探测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 打开摄像头或者打开视频文件\n",
    "cap = cv2.VideoCapture(0)  #参数设为0，可以从摄像头实时采集头像\n",
    "frame_count = 0  #帧计数\n",
    "face_count = 0  #脸部计数\n",
    "\n",
    "# 循环读取每一帧，对每一帧做脸部检测，按ESC键循环结束\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF   # 读键盘\n",
    "    \n",
    "    ret, frame = cap.read()  #从摄像头或者文件中读取一帧\n",
    "    if (ret != True):\n",
    "        print('没有捕获图像，数据采集结束或者检查摄像头是否工作正常！')\n",
    "        break \n",
    "        \n",
    "    frame_count += 1\n",
    " \n",
    "    img_h, img_w, _ = np.shape(frame)  # 获取图像尺寸\n",
    "    \n",
    "    detected = detector(frame, 1)  #对当前帧检测\n",
    "    faces = []   # 脸部图像列表\n",
    "    \n",
    "    if len(detected) > 0:  #当前帧检测到脸部\n",
    "        for i, d in enumerate(detected):\n",
    "            \n",
    "            # 脸部图像坐标与尺寸\n",
    "            x1, y1, x2, y2, w, h = d.left(), d.top(), \\\n",
    "                                   d.right() + 1, d.bottom() + 1, \\\n",
    "                                   d.width(), d.height()\n",
    "            \n",
    "            # 脸部图像坐标\n",
    "            face =  frame[y1:y2 + 1, x1:x2 + 1, :]\n",
    "            face = cv2.resize(face, (128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "            if (key == 32): #空格键采集头像\n",
    "                face_count += 1\n",
    "                file_name = \"./employee/\"+str(frame_count)+str(i)+\".jpg\"\n",
    "                cv2.imwrite(file_name, face)\n",
    "                print('员工照片已经保存到employee目录！！')\n",
    "            elif (key == 27): #ESC键退出\n",
    "                break\n",
    "\n",
    "            # 绘制边界框\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    # 显示单帧检测结果\n",
    "    cv2.imshow(\"Face Detector\", frame) \n",
    "    # Esc键终止检测\n",
    "    if key == 27:\n",
    "        break\n",
    "print('已经完成了 {0} 帧检测，保存了 {1} 幅脸部图像'.format(frame_count, face_count))\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "摆好姿势，按空格键就像按下快门键一样，照片采集到employee目录。可以让同学轮流站到摄像头前，每到这个时候，感觉总是放松好玩的。按下ESC键结束员工照片采集。这些照片将用于人脸实时识别的依据。<br/>\n",
    "接下来，可以检验实战效果了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 加载预训练模型 VGGFace Model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然需要首先加载预训练模型，这个工作在第三阶段做了简化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPool2D, Dense, \\\n",
    "     ZeroPadding2D, Dropout, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGGFace-Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d (ZeroPadding2 (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 1, 2622)        10742334  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2622)              0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2622)              0         \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 按照论文中参数设定，定义VGGFace模型\n",
    "model = Sequential(name = 'VGGFace-Model')\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))  # 输入层\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "          \n",
    "# 模型结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model/vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义特征提取模型，舍去最后一层(即Softmax激活函数层)\n",
    "face_model = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 基于余弦距离对摄像头捕获的人脸实时检测识别\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先对员工照片做特征提取，存入特征字典。实践中特征是存入数据库的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功提取所有员工:dict_keys(['120', '270', '290', '350', 'dongxiangzhi', 'yangshuang'])的特征到数据字典！！\n",
      "Wall time: 496 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "employee_dir = \"./employee/\"   #员工照片目录\n",
    "all_people_faces = dict()  # 员工照片特征字典，临时存储\n",
    "face_h, face_w = 224,224  #模型输入的头像大小\n",
    "\n",
    "# 读取图像并做预处理，用于对员工目录的照片做预处理\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "for file in listdir(employee_dir):  # 遍历员工目录\n",
    "    person, extension = file.split(\".\")\n",
    "    # 析取特征加入字典\n",
    "    all_people_faces[person] = face_model.predict( \\\n",
    "                               preprocess_image(f'./employee/{person}.jpg'))[0,:]\n",
    "\n",
    "print(f\"成功提取所有员工:{all_people_faces.keys()}的特征到数据字典！！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抽样显示某一位员工的脸部特征编码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32678002, -1.2226102 , -0.51887906, ..., -2.1883993 ,\n",
       "        1.5485346 ,  0.8096776 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_people_faces['dongxiangzhi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看特征编码长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2622"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_people_faces['dongxiangzhi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622,)\n"
     ]
    }
   ],
   "source": [
    "print(all_people_faces['dongxiangzhi'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2622,这正是VGGFace的输出维度。有别于FaceNet的128、512维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算余弦距离的函数\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1-(a / (np.sqrt(b) * np.sqrt(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算欧氏距离\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的程序段完成实时检测识别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622,)\n",
      "余弦距离 0.32654738426208496\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.32074403762817383\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.34030604362487793\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.345941960811615\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.25692516565322876\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.1257152557373047\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.13776344060897827\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.18217146396636963\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.17011749744415283\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.15461629629135132\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.23903542757034302\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.25089800357818604\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.3042909502983093\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.13686275482177734\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.3742554783821106\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.31246238946914673\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n",
      "(2622,)\n",
      "余弦距离 0.24421751499176025\n",
      "刷脸认证成功！！120 通过人脸识别，请开闸放行！！\n"
     ]
    }
   ],
   "source": [
    "thresh = 0.4  #设定余弦距离阈值，低于这个值，认为是同一个人\n",
    "\n",
    "# 定义面部正面探测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "#  打开摄像头\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()  #读取一帧\n",
    "    \n",
    "    frame_h, frame_w, _ = np.shape(frame)  # 帧图像大小\n",
    "    detected = detector(frame, 1)  #对当前帧检测\n",
    "    if len(detected) > 0:  #提取当前帧探测的所有脸部图像，构建预测数据集\n",
    "        for i, d in enumerate(detected):  #枚举脸部对象\n",
    "            #脸部坐标\n",
    "            x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n",
    "            # 绘制边界框\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            # 脸部的边界\n",
    "            face =  frame[y1:y2 + 1, x1:x2 + 1, :]\n",
    "            # 脸部缩放，以适合模型需要的输入维度\n",
    "            face = cv2.resize(face, (face_h, face_w))\n",
    "            # 图像归一化\n",
    "            face = face.astype(\"float\") / 255.0\n",
    "            # 扩充维度，变为四维（1，face_h,face_w,3）\n",
    "            face = np.expand_dims(face, axis=0)\n",
    "                        \n",
    "            # 用模型进行特征提取，这是长度为2622的特征向量\n",
    "            captured_representation = face_model.predict(face)[0,:]\n",
    "            print(captured_representation.shape)\n",
    "            # 到员工数据库比对\n",
    "            found = 0\n",
    "            for i in all_people_faces:\n",
    "                person_name = i\n",
    "                representation = all_people_faces[i]\n",
    "\n",
    "                similarity = findCosineSimilarity(representation, \\\n",
    "                             captured_representation)\n",
    "                print('余弦距离',similarity)\n",
    "                if(similarity < thresh):\n",
    "                    cv2.putText(frame, person_name[:], \\\n",
    "                                (d.left(), d.top()-10), \\\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,1.2, \\\n",
    "                                (255, 255, 0), 3)\n",
    "                    print(f'刷脸认证成功！！{person_name} 通过人脸识别，请开闸放行！！')\n",
    "                    found = 1\n",
    "                    break\n",
    "\n",
    "            if(found == 0): # 识别失败\n",
    "                cv2.putText(frame, 'unknown', (d.left(), d.top()-10), \\\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, \\\n",
    "                            (255, 255, 0), 3)\n",
    "                print('刷脸认证失败！！闸门关闭！！')\n",
    "                break\n",
    "\n",
    "    cv2.imshow('Face Recognition',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27: # ESC结束测试\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按ESC键结束测试。对测试结果满意吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color ='red'> 祝贺您已经完成整个项目！！！</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在人脸识别领域，已经初步打通任督二脉，可以通过实践更多的模型和方案作出比较分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
